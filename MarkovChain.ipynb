{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8275c823",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Utilizing Markov Chains with the N-Gram Method to Suggest New Sentences from a Base Text</h1>\n",
    "\n",
    "<br>\n",
    "\n",
    "<b>Project:</b> Markov Chain and N-Grams  \n",
    "<b>Class:</b> Cpts 315 Washington State University  \n",
    "<b>Description:</b> Final Project  \n",
    "<b>By:</b> Kyle Hurd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9f2ee7",
   "metadata": {},
   "source": [
    "# Introduction - Markov Chain\n",
    "\n",
    "A <b>Markov Chain</b> is a model that makes predictions based on a sequence of potential states. It will weigh the probability in which a set of states will be in the sequence and use this information to generate a new sequence. The defining characteristic in which probability is weighed is exclusively dependent on a current state and a passage of time. In other words, past states do not influence the Markov Chain, only the current state. The transition from the current state to the next state in a <b>Markov Chain</b> is determined by using probabilty. The algorithm will consider the probability of a current state transitioning to a potential state and transition based on frequency. \n",
    "\n",
    "---\n",
    "\n",
    "Here is an example to explain the behavior described above. Suppose we have a state machine consisting of two states: State <b>q0</b> represents our initial state. Anything traveling to this state will produce a binary value of <b>1</b>. State <b>q1</b> represents the second state which will produce binary <b>0</b>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603b38eb",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "\n",
    "\n",
    "<img src=\"imgs/two_state_machine.png\"/>\n",
    "\n",
    "\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e9f613",
   "metadata": {},
   "source": [
    "Let us assume the probability in which state <b>q0</b> will transition to <b>q1</b> is 50/50, vice versa.<br><br> \n",
    "\n",
    "```\n",
    "    P(q0|q0) = 0.50\n",
    "    P(q0|q1) = 0.50\n",
    "    P(q1|q0) = 0.50\n",
    "    P(q1|q1) = 0.50\n",
    "```\n",
    "\n",
    "The above probabilities can be read as follows:  \n",
    "\n",
    "```\n",
    "For P(q0|q0), this describes the probability that a transition from state q0 -> q0 will have a frequency of 50%.  \n",
    "\n",
    "For P(q0|q1), this describes the probability that a transition from state q0 -> q1 will have a frequency of 50%.  \n",
    "\n",
    "For P(q1|q0), this describes the probability that a transition from state q1 -> q0 will have a frequency of 50%.  \n",
    "\n",
    "For P(q1|q1), this describes the probability that a transition from state q1 -> q1 will have a frequency of 50%.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da160055",
   "metadata": {},
   "source": [
    "---\n",
    "In the next example, we will generate a generic state machine with a total of three states, increasing the number of potential transitions to three."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9afa8c",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "\n",
    "\n",
    "<img src=\"imgs/three_state_machine.png\"/>\n",
    "\n",
    "\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48cddc89",
   "metadata": {},
   "source": [
    "In this example, we only consider the probabilty of transition from one state to another: information such as the alphabet and grammar are ignored.  \n",
    "\n",
    "The probabilities are listed below:\n",
    "\n",
    "```\n",
    "P(q0|q0) = 0.20\n",
    "P(q0|q1) = 0.40\n",
    "P(q0|q2) = 0.20\n",
    "\n",
    "P(q1|q0) = 0.50\n",
    "P(q1|q1) = 0.25\n",
    "P(q1|q1) = 0.25\n",
    "\n",
    "P(q2|q0) = 0.10\n",
    "P(q2|q1) = 0.80\n",
    "P(q2|q2) = 0.10\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad862e27",
   "metadata": {},
   "source": [
    "## Setting up the Code\n",
    "\n",
    "---\n",
    "\n",
    "First we need to initalize a class with all the information we will need\n",
    "for a Markoc Chain. Here are a few that we will need:\n",
    "\n",
    "- a list of words from our source text for which to build the chain.\n",
    "- a dictionary to store the n-grams and list of next words.\n",
    "- the name of the source file (in case of accessing later.\n",
    "\n",
    "I also thought it would be cool to hold some information regarding the total number of\n",
    "characters, words, and unique words in the text. We will store this information in a dataclass.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53016424",
   "metadata": {},
   "outputs": [],
   "source": [
    "# JDC used to extend a Class Object in Jupyter Notebook\n",
    "import jdc\n",
    "\n",
    "\n",
    "import random\n",
    "from colorama import Fore, Style\n",
    "from dataclasses import dataclass\n",
    "from functools import reduce\n",
    "\n",
    "HUNGER_GAMES_FILENAME = './data/hunger_games.txt'\n",
    "\n",
    "STOP_CHARACTERS = '.?!'\n",
    "STOP_WORDS = ['Dr.', 'Jr.', 'Sr.', 'Mr.', 'Mrs.', 'Ms.', 'Miss.', 'Prof.']\n",
    "FULL_QUOTE = '\"'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c0ce22",
   "metadata": {},
   "source": [
    "## TextSpecs DataClass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c64ae4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class TextSpecs:\n",
    "    num_chars: int = 0\n",
    "    num_words: int = 0\n",
    "    num_unique_words: int = 0\n",
    "        \n",
    "        \n",
    "    def _populate(self, num_chars: int, num_words: int, num_unique_words: int):\n",
    "        self.num_chars += num_chars\n",
    "        self.num_words += num_words\n",
    "        self.num_unique_words += num_unique_words\n",
    "        \n",
    "        \n",
    "    def display_specs(self):\n",
    "        print(f'{Style.BRIGHT}{Fore.LIGHTGREEN_EX}{\"#\" * 18}' \\\n",
    "              f'{\"#\" * (len(str(self.num_unique_words)) + 1)}{Style.RESET_ALL}')\n",
    "        \n",
    "        print(f'{Style.BRIGHT}num chars: {Style.RESET_ALL}{self.num_chars}{Style.RESET_ALL} ')\n",
    "        print(f'{Style.BRIGHT}num words: {Style.RESET_ALL}{self.num_words}{Style.RESET_ALL} ')\n",
    "        print(f'{Style.BRIGHT}num unique words: {Style.RESET_ALL}{self.num_unique_words}{Style.RESET_ALL} ')\n",
    "        \n",
    "        print(f'{Style.BRIGHT}{Fore.LIGHTGREEN_EX}{\"#\" * 18}' \\\n",
    "              f'{\"#\" * (len(str(self.num_unique_words)) + 1)}{Style.RESET_ALL}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf3cda0b",
   "metadata": {},
   "source": [
    "## MarkovChain Class\n",
    "\n",
    "---\n",
    "\n",
    "Below is the initializer for the MarkovChain. It also defines `display_specs` which utilizes the `TextSpecs`\n",
    "dataclass defined above to print out information regarding the text(s) we are using. It is important to note\n",
    "that `TextSpecs.populate()` keeps the original values and adds to it using the augmented assignment operator. This\n",
    "means we should not call these functions directly in practice, but should use the wrapper function defined further\n",
    "down the page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c073f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MarkovChain:\n",
    "    \n",
    "    def __init__(self, filenames: list, N: int=3, stop_characters=None, stop_words=None):\n",
    "        self.initial_words = []\n",
    "        self.n_grams = {}\n",
    "        self.starting_n_grams = []\n",
    "        self.filenames = filenames\n",
    "        self.stop_characters = stop_characters\n",
    "        self.stop_words = stop_words\n",
    "        self.N = N\n",
    "        self.specs = TextSpecs()\n",
    "        \n",
    "    \n",
    "    def display_specs(self):\n",
    "        print(f'{Style.BRIGHT}Files:{Style.RESET_ALL}')\n",
    "        for filename in self.filenames:\n",
    "            print(f'{Style.BRIGHT}{Fore.LIGHTRED_EX}-{Style.RESET_ALL} {filename}')\n",
    "        self.specs.display_specs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113cd2bf",
   "metadata": {},
   "source": [
    "\n",
    "    For the methods below, these will be wrapped with a function to keep the proper\n",
    "    states of the initialized variables within `MarkovChain` and `TextSpecs`\n",
    "\n",
    "## MarkovChain._init_words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d0f9962",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%add_to MarkovChain\n",
    "\n",
    "def _init_words(self):\n",
    "    \n",
    "    for filename in self.filenames:\n",
    "        with open(filename, 'r') as f:\n",
    "            chars = f.read()\n",
    "            words = chars.split()\n",
    "            unique_words = set(words)\n",
    "            self.specs._populate(len(chars), len(words), len(unique_words))\n",
    "            self.initial_words.extend(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b066d0e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mFiles:\u001b[0m\n",
      "\u001b[1m\u001b[91m-\u001b[0m ./data/hunger_games.txt\n",
      "\u001b[1m\u001b[92m#######################\u001b[0m\n",
      "\u001b[1mnum chars: \u001b[0m27113\u001b[0m \n",
      "\u001b[1mnum words: \u001b[0m5081\u001b[0m \n",
      "\u001b[1mnum unique words: \u001b[0m1914\u001b[0m \n",
      "\u001b[1m\u001b[92m#######################\u001b[0m\n",
      "\n",
      "\u001b[1mPreview of the Text:\u001b[0m\n",
      "When I wake up, the other side of the bed is cold. My fingers stretch out, seeking Prim’s warmth but finding only the rough canvas cover of the mattress. She must have had bad dreams and climbed in with our mother. Of course, she did. This is the day of "
     ]
    }
   ],
   "source": [
    "mc = MarkovChain(filenames=[HUNGER_GAMES_FILENAME],\n",
    "                 N=3,\n",
    "                 stop_characters=STOP_CHARACTERS,\n",
    "                 stop_words=STOP_WORDS\n",
    "                )\n",
    "\n",
    "mc._init_words()\n",
    "mc.display_specs()\n",
    "\n",
    "print(f'\\n{Style.BRIGHT}Preview of the Text:{Style.RESET_ALL}')\n",
    "for i in range(50):\n",
    "    print(mc.initial_words[i], end=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5121a3",
   "metadata": {},
   "source": [
    "## MarkovChain._create_ngram_dict()\n",
    "\n",
    "This is where the probability between states comes in to play. Note here, when we add the next word beyond the\n",
    "n-gram (the Nth + 1 word), we allow duplicates into the list. This means we could recieve a list such as \n",
    "`[the, The, the, tiny]` where 75% of the words are `the` and 25% are `tiny`. When selecting from this list\n",
    "in the future, this means that if we select from the bag of words randomly, we should see a selection of the\n",
    "word `the` approximately 75% of the time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97227460",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%add_to MarkovChain\n",
    "\n",
    "def _create_ngram_dict(self):\n",
    "    n_grams = zip(*[self.initial_words[i:] for i in range(self.N + 1)])\n",
    "    for n_gram in n_grams:\n",
    "        key = n_gram[:self.N]\n",
    "        next_word = n_gram[-1]\n",
    "        self.n_grams[key] = self.n_grams.get(key, []) + [next_word]\n",
    "        \n",
    "        \n",
    "def _create_starting_ngram_list(self):\n",
    "    \n",
    "    is_valid      = lambda g: g[0] not in self.stop_words and (g[1][0].isupper() or g[1][0] in [\"'\", '\"'])\n",
    "    in_stop_chars = lambda g: g[0][-1] in self.stop_characters\n",
    "    \n",
    "    n_grams = zip(*[self.initial_words[i:] for i in range(self.N + 1)])\n",
    "    for n_gram in n_grams:\n",
    "        if in_stop_chars(n_gram) and is_valid(n_gram):\n",
    "            self.starting_n_grams.append(n_gram[1:])\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416a7d12",
   "metadata": {},
   "source": [
    "## Preview Results from the N-Grams and the Entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe3c3c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mPreview of N-Grams:\u001b[0m\n",
      "\u001b[1m- \u001b[0m\u001b[92m('When', 'I', 'wake')\u001b[0m\n",
      "\u001b[1m- \u001b[0m\u001b[92m('I', 'wake', 'up,')\u001b[0m\n",
      "\u001b[1m- \u001b[0m\u001b[92m('wake', 'up,', 'the')\u001b[0m\n",
      "\u001b[1m- \u001b[0m\u001b[92m('up,', 'the', 'other')\u001b[0m\n",
      "\u001b[1m- \u001b[0m\u001b[92m('the', 'other', 'side')\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "mc.n_grams = {} # Only used because we are calling this multiple times.\n",
    "\n",
    "mc._create_ngram_dict()\n",
    "n_gram_vals = list(mc.n_grams.values())\n",
    "\n",
    "print(f'\\n{Style.BRIGHT}Preview of N-Grams:{Style.RESET_ALL}')\n",
    "for i, key in enumerate(mc.n_grams.keys()):\n",
    "    if i == 5:\n",
    "        break\n",
    "    print(f'{Style.BRIGHT}- {Style.RESET_ALL}{Fore.LIGHTGREEN_EX}{key}{Style.RESET_ALL}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb3a93f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mPreview of the N-Gram Entries:\u001b[0m\n",
      "\u001b[1m- \u001b[0m\u001b[92mup,\u001b[0m \n",
      "\u001b[1m- \u001b[0m\u001b[92mthe\u001b[0m \n",
      "\u001b[1m- \u001b[0m\u001b[92mother\u001b[0m \n",
      "\u001b[1m- \u001b[0m\u001b[92mside\u001b[0m \n",
      "\u001b[1m- \u001b[0m\u001b[92mof\u001b[0m \n",
      "\u001b[1m- \u001b[0m\u001b[92mhad\u001b[0m \u001b[92mreally\u001b[0m \n",
      "\u001b[1m- \u001b[0m\u001b[92mday\u001b[0m \u001b[92mclosest\u001b[0m \n",
      "\u001b[1m- \u001b[0m\u001b[92m12,\u001b[0m \u001b[92m12.\u001b[0m \n",
      "\u001b[1m- \u001b[0m\u001b[92mnicknamed\u001b[0m \u001b[92mis\u001b[0m \n",
      "\u001b[1m- \u001b[0m\u001b[92monly\u001b[0m \u001b[92mtry\u001b[0m \n"
     ]
    }
   ],
   "source": [
    "print(f'\\n{Style.BRIGHT}Preview of the N-Gram Entries:{Style.RESET_ALL}')\n",
    "for n_gram in n_gram_vals[:5]:\n",
    "    print(f'{Style.BRIGHT}- {Style.RESET_ALL}', end='')\n",
    "    for gram in n_gram:\n",
    "        print(f'{Fore.LIGHTGREEN_EX}{gram}{Style.RESET_ALL}', end=' ')\n",
    "    print()\n",
    "    \n",
    "n_gram_new = list(filter(lambda x: len(x) > 1, n_gram_vals))\n",
    "for entries in n_gram_new[:5]:\n",
    "    print(f'{Style.BRIGHT}- {Style.RESET_ALL}', end='')\n",
    "    for entry in entries:\n",
    "        print(f'{Fore.LIGHTGREEN_EX}{entry}{Style.RESET_ALL}', end=' ')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce6598b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mPreview of the N-Gram Starters:\u001b[0m\n",
      "\u001b[1m- \u001b[0m\u001b[92m('My', 'fingers', 'stretch')\u001b[0m\n",
      "\u001b[1m- \u001b[0m\u001b[92m('She', 'must', 'have')\u001b[0m\n",
      "\u001b[1m- \u001b[0m\u001b[92m('Of', 'course,', 'she')\u001b[0m\n",
      "\u001b[1m- \u001b[0m\u001b[92m('This', 'is', 'the')\u001b[0m\n",
      "\u001b[1m- \u001b[0m\u001b[92m('I', 'prop', 'myself')\u001b[0m\n",
      "\u001b[1m- \u001b[0m\u001b[92m('There’s', 'enough', 'light')\u001b[0m\n",
      "\u001b[1m- \u001b[0m\u001b[92m('My', 'little', 'sister,')\u001b[0m\n",
      "\u001b[1m- \u001b[0m\u001b[92m('In', 'sleep,', 'my')\u001b[0m\n",
      "\u001b[1m- \u001b[0m\u001b[92m('Prim’s', 'face', 'is')\u001b[0m\n",
      "\u001b[1m- \u001b[0m\u001b[92m('My', 'mother', 'was')\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "mc.starting_n_grams = [] # Only used because we are calling this multiple times.\n",
    "\n",
    "mc._create_starting_ngram_list()\n",
    "print(f'\\n{Style.BRIGHT}Preview of the N-Gram Starters:{Style.RESET_ALL}')\n",
    "for n_gram in mc.starting_n_grams[:10]:\n",
    "    print(f'{Style.BRIGHT}- {Style.RESET_ALL}{Fore.LIGHTGREEN_EX}{n_gram}{Style.RESET_ALL}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b96401",
   "metadata": {},
   "source": [
    "## MarkovChain.generate_sentence [1st iteration]\n",
    "\n",
    "This is the initial draft of the generate_sentence method. It it actually generates\n",
    "understandable text and was my first solution that showed a promising output return.\n",
    "The key to making this function work was to separate the n-grams with n-grams that can\n",
    "start a sentence. These are `self.n_grams` and `self.starting_n_grams`, respectively.\n",
    "\n",
    "By intializing with an n-gram that is the beginning of a sentence,\n",
    "We can start the chain from the beginning of the sentence instead of midway through or at the end.\n",
    "This solution shows another issue: the sentences that it has generated, although somewhat coherent,\n",
    "end midway through a sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4fa210f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%add_to MarkovChain\n",
    "\n",
    "def generate_sentence(self):\n",
    "    \n",
    "    length_sentence = random.randint(4, 15)  \n",
    "    seed = random.choice(self.starting_n_grams)\n",
    "    output = [x for x in seed]\n",
    "    for _ in range(length_sentence):\n",
    "        word = random.choice(self.n_grams[seed])\n",
    "        seed = tuple(list(seed[1:]) + [word])\n",
    "        output.append(word)\n",
    "        \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef916dce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mPreview of Generated Sentences:\u001b[0m\n",
      "\u001b[1m\u001b[31m- \u001b[0mMost of the Peacekeepers turn a blind eye to the few of us \n",
      "\u001b[1m\u001b[31m- \u001b[0mEven so, I always take a moment to listen carefully for the \n",
      "\u001b[1m\u001b[31m- \u001b[0mWe rarely talk, which suits us both just fine. Today her \n",
      "\u001b[1m\u001b[31m- \u001b[0mGale, who is eighteen and has been either helping or \n",
      "\u001b[1m\u001b[31m- \u001b[0mMy mother wears a fine dress from her apothecary days. Prim is in my first \n"
     ]
    }
   ],
   "source": [
    "print(f'{Style.BRIGHT}Preview of Generated Sentences:{Style.RESET_ALL}')\n",
    "for _ in range(5):\n",
    "    print(f'{Style.BRIGHT}{Fore.RED}- {Style.RESET_ALL}', end='')\n",
    "    for word in mc.generate_sentence():\n",
    "        print(word, end=' ')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1702b290",
   "metadata": {},
   "source": [
    "## MarkovChain.generate_sentence [2nd iteration]\n",
    "\n",
    "In this second iteration, I address the issue where the sentence ends halfway through. Additionally,\n",
    "a few times in the iteration one implementation, there is sometimes a random quotation that tries to\n",
    "start a quote or end a quote. This will also be addressed in this iteration. Testing for a quote at\n",
    "the beginning or end is also quite a difficult problem to fix in a simple way. Somehow, we have to keep\n",
    "track of the current state the generator is in (does it need to search for an ending quote, has it seen\n",
    "a closing quote but no opening quote?). The second problem is more challenging. It is pretty straightforward\n",
    "to search for a closing quote after seeing an opening, but what are we to do if we see a closing quote?\n",
    "\n",
    "\n",
    "To be honest, I don't have a good solution to this issue. One \"solution\" would be to eliminate the quotes\n",
    "all-together from the generator, but that is no fun. The next solution could be to insert the starting quote\n",
    "at the start of the previous sentence, but there are too many conditions to consider. For example,\n",
    "\n",
    "- She said, \"Hello, foo! How is bar?\"\n",
    "- \"Hello, foo!\" she said, \"How is bar?\"\n",
    "- \"Hello, foo! How is bar?\" She said.\n",
    "\n",
    "In the first example, we can't just insert the start quote at the beginning of the sentence, as that would\n",
    "be incorrect. Additionally, the second condition is even harder, for we have to potentially insert two quotes\n",
    "in one sentence! The last example would be the only time where the \"fix\" would work as intended. The problem\n",
    "with the first two examples are the word \"said\" or \"she\" can be replaced with too many different words such\n",
    "as \"He\", \"Jared\", or \"exlaimed\", \"cried.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6f408518",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%add_to MarkovChain\n",
    "\n",
    "def generate_sentence(self):\n",
    "    \n",
    "    length_sentence = random.randint(4, 15)  \n",
    "    seed = random.choice(self.starting_n_grams)\n",
    "    \n",
    "    \n",
    "    output = [x for x in seed]\n",
    "    is_quote = reduce(lambda base, word: (word[0] == FULL_QUOTE) or base, output, False)\n",
    "\n",
    "    for _ in range(length_sentence):\n",
    "        word, seed = self._generate_word(seed, is_quote)\n",
    "        output.append(word)\n",
    "        \n",
    "    self._end_sentence(output, seed, is_quote)\n",
    "    return output      \n",
    "\n",
    "\n",
    "def _generate_word(self, seed, is_quote=False):\n",
    "    \n",
    "    not_ending_quote = lambda word: word[-1] != FULL_QUOTE\n",
    "    \n",
    "    words = self.n_grams[seed]\n",
    "    words = [word for word in words if not_ending_quote(word)] if not is_quote else words\n",
    "    word = random.choice(words)\n",
    "    seed = tuple(list(seed[1:]) + [word])\n",
    "    \n",
    "    return word, seed\n",
    "    \n",
    "\n",
    "def _end_sentence(self, output, seed, is_quote=False):\n",
    "    \n",
    "    in_stop_characters = lambda word: word[-1] in self.stop_characters\n",
    "    in_stop_words      = lambda word: word in self.stop_words\n",
    "    \n",
    "    while not (end := [word for word in self.n_grams[seed] if in_stop_characters(word) and not in_stop_words(word)]):\n",
    "        word, seed = self._generate_word(seed, is_quote)\n",
    "        is_quote |= word[0] == FULL_QUOTE  # if quote at beginning, make true.\n",
    "        is_quote &= word[-1] != FULL_QUOTE # if quote at end, make false.\n",
    "        output.append(word)\n",
    "        \n",
    "    word = random.choice(end)\n",
    "    n_gram = tuple(list(seed[1:]) + [word])\n",
    "    output.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "acf0c5e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mPreview of Generated Sentences [Iteration 2]:\u001b[0m\n",
      "\u001b[1m\u001b[31m- \u001b[0mBut today, despite the bright banners hanging on the buildings, there’s an air of grimness. \n",
      "\u001b[1m\u001b[31m- \u001b[0mHow could I leave Prim, who is the only person in the world I’m certain I love? \n",
      "\u001b[1m\u001b[31m- \u001b[0mSupple leather that has molded to my feet. I pull on trousers, a shirt, tuck my long dark braid up into a cap, and grab my forage bag. \n",
      "\u001b[1m\u001b[31m- \u001b[0mI had six when I was just twelve years old.” “That’s not her fault,” I say. \n",
      "\u001b[1m\u001b[31m- \u001b[0mEven here, even in the middle of nowhere, you worry someone might overhear you. \n"
     ]
    }
   ],
   "source": [
    "print(f'{Style.BRIGHT}Preview of Generated Sentences [Iteration 2]:{Style.RESET_ALL}')\n",
    "for _ in range(5):\n",
    "    sentence = mc.generate_sentence()\n",
    "    print(f'{Style.BRIGHT}{Fore.RED}- {Style.RESET_ALL}', end='')\n",
    "    for word in sentence:\n",
    "        print(word, end=' ')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc694016",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Cpts-315-Markov-Chain",
   "language": "python",
   "name": "cpts-315-markov-chain"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
